{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.4.1'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "train_images = (train_images - 127.5) / 127.5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f03981f0d90>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen = make_generator_model()\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_img = gen(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_img[0, :, :, 0], cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.00366776]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_img)\n",
    "print(decision)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator = gen,\n",
    "                                 discriminator=discriminator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = gen(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, gen.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, gen.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as we go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(gen,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(gen,\n",
    "                           epochs,\n",
    "                           seed)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "in user code:\n\n    <ipython-input-34-5ad21963e7ed>:8 train_step  *\n        generated_images = generator(noise, training=True)\n\n    NameError: name 'generator' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-41-d152560ca122>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_dataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mEPOCHS\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-39-5ef0b36d2075>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(dataset, epochs)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mimage_batch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m       \u001B[0mtrain_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage_batch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0;31m# Produce images for the GIF as we go\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/EPQ/CompetitionSystem/venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    826\u001B[0m     \u001B[0mtracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    827\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtm\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 828\u001B[0;31m       \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    829\u001B[0m       \u001B[0mcompiler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"xla\"\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_experimental_compile\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m\"nonXla\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    830\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/EPQ/CompetitionSystem/venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    860\u001B[0m       \u001B[0;31m# In this case we have not created variables on the first call. So we can\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    861\u001B[0m       \u001B[0;31m# run the first trace but we should fail if variables are created.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 862\u001B[0;31m       \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    863\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_created_variables\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    864\u001B[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001B[0;32m~/Documents/EPQ/CompetitionSystem/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2939\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2940\u001B[0m       (graph_function,\n\u001B[0;32m-> 2941\u001B[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0m\u001B[1;32m   2942\u001B[0m     return graph_function._call_flat(\n\u001B[1;32m   2943\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001B[0;32m~/Documents/EPQ/CompetitionSystem/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_maybe_define_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   3359\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3360\u001B[0m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmissed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcall_context_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3361\u001B[0;31m           \u001B[0mgraph_function\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_graph_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3362\u001B[0m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprimary\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcache_key\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3363\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/EPQ/CompetitionSystem/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_create_graph_function\u001B[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m   3204\u001B[0m             \u001B[0marg_names\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0marg_names\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3205\u001B[0m             \u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3206\u001B[0;31m             capture_by_value=self._capture_by_value),\n\u001B[0m\u001B[1;32m   3207\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_attributes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3208\u001B[0m         \u001B[0mfunction_spec\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunction_spec\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/EPQ/CompetitionSystem/venv/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m    988\u001B[0m         \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moriginal_func\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf_decorator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munwrap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpython_func\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    989\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 990\u001B[0;31m       \u001B[0mfunc_outputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpython_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mfunc_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfunc_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    991\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    992\u001B[0m       \u001B[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/EPQ/CompetitionSystem/venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36mwrapped_fn\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m    632\u001B[0m             \u001B[0mxla_context\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mExit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    633\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 634\u001B[0;31m           \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mweak_wrapped_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__wrapped__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    635\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    636\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/EPQ/CompetitionSystem/venv/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    975\u001B[0m           \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint:disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    976\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"ag_error_metadata\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 977\u001B[0;31m               \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    978\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    979\u001B[0m               \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: in user code:\n\n    <ipython-input-34-5ad21963e7ed>:8 train_step  *\n        generated_images = generator(noise, training=True)\n\n    NameError: name 'generator' is not defined\n"
     ]
    }
   ],
   "source": [
    "train(train_dataset, EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}